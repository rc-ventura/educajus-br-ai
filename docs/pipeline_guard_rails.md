[Skip to content](https://chatgpt.com/g/g-p-68f2224a20f081918feb76d0b8b0f110/c/68f3bdd7-17f4-832b-a761-68e37159ba4b#main)

# IA no Direito Brasileiro: Soluções Inovadoras e Uso de *Guardrails*

## Pipeline Multi-Camadas de *Guardrails* (Redução de Alucinações)

![https://github.com/FareedKhan-dev/agentic-guardrails](blob:https://chatgpt.com/82bf20b0-228e-4c07-b822-bf5d5777e696)

*Figura: Exemplo de pipeline avançado com múltiplas camadas de **guardrails** para agentes de IA. O Layer 1 filtra entradas maliciosas, o Layer 2 valida o plano de ação interno do agente, e o Layer 3 sanitiza a resposta final antes de enviá-la ao usuário.*

 Uma recente abordagem para aumentar a confiabilidade de sistemas de IA é a implantação de *guardrails* (trilhos de segurança) em múltiplas camadas. Em essência, a ideia é criar um **pipeline de defesa em profundidade** para agentes de IA ou soluções de *Retrieval-Augmented Generation* (RAG). Cada camada atua como uma barreira independente para mitigar riscos como alucinações (invenção de fatos), violações de compliance, prompts maliciosos ou saídas inadequadas[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=Guardrails,includes%20components%20such%20as%20%E2%80%A6)[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,it%E2%80%99s%20sent%20to%20the%20user). Por exemplo, no **Layer 1 (Entrada)** o sistema realiza verificações rápidas na consulta do usuário, bloqueando imediatamente entradas maliciosas, irrelevantes ou que violem políticas antes que cheguem ao agente principal[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,it%E2%80%99s%20sent%20to%20the%20user). Em seguida, o **Layer 2 (Plano de Ação)** inspeciona o raciocínio interno ou *chain-of-thought* do agente, validando o plano de ação gerado. Se o agente planeja uma ação arriscada ou contrária às regras, essa camada pode barrar ou ajustar o curso antes da execução[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=agent.%20,compliant%20intentions%20before%20execution). Por fim, o **Layer 3 (Saída)** atua como um filtro final sobre a resposta produzida: verifica se há informações imprecisas ou potencialmente inseguras, assegura conformidade jurídica e sanitiza a linguagem antes de apresentar o resultado ao usuário[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=before%20execution.%20,it%E2%80%99s%20sent%20to%20the%20user). Esse modelo em três camadas — entrada segura, plano monitorado e saída verificada — garante que mesmo que alguma falha passe por uma camada, outra mais adiante possa detectá-la e corrigi-la[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=Guardrails,includes%20components%20such%20as%20%E2%80%A6)[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,it%E2%80%99s%20sent%20to%20the%20user). Em implementações recentes, essa abordagem incluiu até uma etapa de **verificação de citações e fatos** no Layer 3, visando reduzir drasticamente as alucinações factuais em domínios críticos[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,Integration%20and%20The%20Aegis%20Scorecard).

 No contexto jurídico, um pipeline multi-camadas de guardrails é especialmente valioso. Considere que advogados dependem da exatidão de citações de leis e jurisprudências nos documentos: uma IA generativa sem controles pode inventar precedentes ou artigos de lei inexistentes, o que é inaceitável. Houve caso no Brasil em que um advogado apresentou um Habeas Corpus redigido por IA contendo  **jurisprudência falsa** , tentando induzir erro no tribunal – o que levou a advertência formal pelo TJ/SC[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). *Guardrails* bem projetados podem prevenir esse tipo de situação, pois obrigariam o sistema a **fundamentar cada afirmação em fontes confiáveis** ou alertariam o usuário sobre conteúdo não verificado. Além disso, camadas de segurança podem impor limites éticos e de conformidade: por exemplo, bloqueando respostas que violem o Código de Ética da OAB ou que exponham dados sigilosos de clientes. Assim, inspirando-se nesse artigo de Fareed Khan (2025) sobre  *“Agentic Guardrail Pipeline”* , pode-se integrar um **assistente jurídico de IA** com múltiplos filtros de segurança, ganhando a confiança dos profissionais do Direito ao minimizar alucinações e riscos legais[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,it%E2%80%99s%20sent%20to%20the%20user).

## O Protocolo  *Aegis* : Segurança Formal para Agentes Autônomos de IA

Enquanto os *guardrails* acima tratam de filtragens e validações mais voltadas ao conteúdo gerado, o **Protocolo Aegis** (proposto por Adapala & Alugubelly, 2025) traz uma perspectiva complementar de **segurança de infraestrutura** para ecossistemas de agentes de IA. Trata-se de um **framework de segurança fundamentado** em três pilares tecnológicos[arxiv.org](https://arxiv.org/abs/2508.19267#:~:text=failures%2C%20that%20traditional%20cybersecurity%20paradigms,Our%20quantitative%20evaluation): *(1)* **Identidade não-falsificável** dos agentes via identificadores descentralizados (DIDs), garantindo que cada agente possua credenciais únicas e verificáveis; *(2)* **Integridade na comunicação** entre agentes, utilizando criptografia pós-quântica padronizada pelo NIST, para evitar interceptações ou alterações maliciosas nas mensagens trocadas; e *(3)*  **Compliance verificável por provas de conhecimento zero (ZKP)** , através do sistema Halo2, assegurando que agentes ajam conforme políticas pré-definidas **sem expor dados sensíveis**[arxiv.org](https://arxiv.org/abs/2508.19267#:~:text=failures%2C%20that%20traditional%20cybersecurity%20paradigms,Our%20quantitative%20evaluation). Em outras palavras, um agente poderia provar criptograficamente que seguiu certas regras (por exemplo, “não acessar dados sigilosos além do escopo permitido”) sem revelar qual dado específico foi acessado, graças às ZKPs.

 Os autores do Aegis validaram o protocolo contra um modelo de adversário avançado e o avaliaram via simulação com 1.000 agentes, observando **taxa de sucesso zero** para 20 mil tentativas de ataque quando as camadas Aegis estavam ativadas[arxiv.org](https://arxiv.org/abs/2508.19267#:~:text=preserving%20policy%20compliance%20using%20the,a%20reproducible%20baseline%20for%20future). Isso sugere que a combinação de identidade forte, comunicações seguras e cumprimento verificável de regras pode praticamente blindar um sistema multiagente contra diversos vetores de ataque. Embora esse nível de segurança seja avançado e voltado a agentes autônomos complexos, **os conceitos podem inspirar soluções jurídicas** inovadoras. Por exemplo, em um projeto de IA jurídica, poderíamos implementar **identificação segura de agentes** para assegurar que apenas usuários/autores autorizados gerem certos tipos de documentos, e usar criptografia robusta para proteger comunicações envolvendo dados de clientes (conforme exige a confidencialidade profissional). Além disso, o uso de **políticas verificáveis** via algoritmos de compliance poderia garantir aderência à LGPD e outras normas: cada resposta do agente viria acompanhada de uma “prova” de que nenhum dado pessoal foi indevidamente exposto durante o processamento, por exemplo. Em suma, o protocolo Aegis mostra que é possível elevar a confiança em agentes de IA a um patamar quase  *à prova de falhas* , algo desejável em aplicações críticas como no Direito[arxiv.org](https://arxiv.org/abs/2508.19267#:~:text=failures%2C%20that%20traditional%20cybersecurity%20paradigms,Our%20quantitative%20evaluation)[arxiv.org](https://arxiv.org/abs/2508.19267#:~:text=validate%20the%20protocol%20against%20the,for%20safe%2C%20scalable%20autonomous%20AI).

## Hackathon de IA da OAB-PR: Objetivos e Contexto

O terceiro link fornecido é a notícia oficial do  **Hackathon de Inteligência Artificial da OAB Paraná 2025** , que estabelece o cenário onde essa pesquisa será aplicada. Trata-se de uma maratona de inovação nos dias 6 e 7 de dezembro de 2025 (inscrições de 21/10 a 24/11) voltada à **criação de soluções jurídicas abertas usando IA**[oabpr.org.br](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=A%20OAB%20Paran%C3%A1%20abre%20na,sede%20da%20seccional%2C%20em%20Curitiba)[oabpr.org.br](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=O%20desafio%20proposto%20pelo%20Hackathon,aplica%C3%A7%C3%A3o%20pr%C3%A1tica%20e%20documenta%C3%A7%C3%A3o%20aberta). Diferentemente de hackathons tradicionais de programação pura, este evento foca em  **engenharia de *prompts* e agentes inteligentes** , incentivando participantes a utilizarem modelos já disponíveis (GPT-4, Microsoft Copilot, Claude, Gemini, etc.) para resolver problemas reais da advocacia e ampliar o acesso à Justiça[oabpr.org.br](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=O%20desafio%20proposto%20pelo%20Hackathon,aplica%C3%A7%C3%A3o%20pr%C3%A1tica%20e%20documenta%C3%A7%C3%A3o%20aberta). Ou seja, não é obrigatório saber codar; o diferencial estará na criatividade da ideia, na aplicação prática e na documentação. A OAB-PR enfatiza que **todos os projetos deverão ter formato aberto e código/documentação disponibilizados em repositório público** sob licença permissiva[oabpr.org.br](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=documenta%C3%A7%C3%A3o%20aberta). Essa política de *open source* visa possibilitar que as soluções criadas sejam adotadas e aprimoradas posteriormente por escritórios, departamentos jurídicos e profissionais de todo o país, maximizando o impacto.

 Os critérios de avaliação incluem  **inovação** ,  **aplicabilidade prática** , **clareza da documentação** e **impacto social**[oabpr.org.br](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=As%20tr%C3%AAs%20equipes%20com%20os,e%20impacto%20social%20da%20proposta). As equipes vencedoras (compostas por 3 a 6 integrantes, incluindo ao menos dois advogados ou estudantes de Direito) receberão prêmios em dinheiro e serão julgadas por uma banca mista de especialistas do meio jurídico e tecnológico[oabpr.org.br](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=As%20tr%C3%AAs%20equipes%20com%20os,e%20impacto%20social%20da%20proposta). Esse contexto deixa claro que, para se destacar, um projeto deve apresentar  **originalidade na ideia** , ao mesmo tempo em que resolve um problema concreto dos profissionais do Direito ou da sociedade (acesso à informação e Justiça), e que tenha potencial de ser usado na prática real. Além disso, a menção específica a “prompts e agentes” indica que soluções envolvendo **Agentes de IA encadeados, fluxos automáticos de trabalho com LLMs, ou integrações criativas entre ferramentas** estão alinhadas ao que os organizadores esperam. Em suma, o hackathon da OAB-PR é uma oportunidade de propor um  **protótipo inovador de IA jurídica** , aproveitando tecnologias de ponta já existentes, mas customizando-as ao contexto brasileiro e aos valores da advocacia (ética, privacidade, acesso equânime).

## Soluções de IA já Aplicadas no Direito Brasileiro

Antes de delinear novas ideias, vale mapear brevemente o estado atual das  **ferramentas de IA jurídica no Brasil** , até para identificar lacunas a serem preenchidas. Nos últimos anos, surgiram diversas soluções comerciais e experimentais integrando IA ao cotidiano dos advogados brasileiros:

* **Automação de Documentos e Peças Processuais:** Ferramentas como  *Jurídico AI* ,  *Lawx.ai* , *ChatADV* e *Cria.AI* permitem gerar petições, contratos e pareceres automaticamente a partir de poucos dados de entrada. Essas IAs são  **treinadas especificamente em legislação, jurisprudência e doutrina brasileiras** , garantindo que a linguagem jurídica e os fundamentos legais estejam alinhados ao ordenamento nacional[juridico.ai](https://juridico.ai/#:~:text=Pe%C3%A7as%20geradas%20por%20uma%20IA,treinada%20em%20direito%20brasileiro)[juridico.ai](https://juridico.ai/#:~:text=Suas%20pe%C3%A7as%20criadas%20por%20uma,legisla%C3%A7%C3%A3o%2C%20jurisprud%C3%AAncia%20e%20doutrina%20brasileiras). Por exemplo, a plataforma Jurídico AI afirma ter uma IA atualizada diariamente com leis e jurisprudência do país, capaz de produzir peças personalizadas de alta qualidade em minutos[juridico.ai](https://juridico.ai/#:~:text=Gere%20pe%C3%A7as%20espec%C3%ADficas%20para%20os,seus%20casos%20jur%C3%ADdicos)[juridico.ai](https://juridico.ai/#:~:text=Tenha%20pe%C3%A7as%20completas%20e%20ricas,com%20informa%C3%A7%C3%A3o%20jur%C3%ADdica%20consistente). Já a Cria.AI destaca que seus documentos vêm com  **“embasamento rastreável e jurisprudências reais e precisas”** , contabilizando milhares de horas de trabalho poupadas aos advogados[criaai.app.br](https://criaai.app.br/#:~:text=A%C2%A0Cria,performance%20para%20profissionais%20do%20direito). Ou seja, há um esforço claro de diferenciar essas ferramentas de um ChatGPT genérico, oferecendo conteúdo já fundamentado nas fontes corretas (o que sugere uso de técnicas de *retrieval* ou bases de dados internas). Ainda assim, a cautela é necessária: mesmo soluções boas podem eventualmente referenciar casos equivocados, cabendo ao advogado revisar o material.
* **Pesquisa Jurídica e Jurisprudência:** A busca por precedentes e entendimentos jurisprudenciais ganhou agilidade com IAs como *Turivius* e  *Inspira* . Essas plataformas utilizam NLP para  **organizar e resumir decisões judiciais** , permitindo encontrar precedentes relevantes de forma mais eficiente do que pesquisas manuais em diários oficiais[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). O Inspira, por exemplo, fornece *resumos automáticos de decisões* e até colaboração em tempo real na análise de documentos legais[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). Isso facilita o trabalho, mas novamente depende-se da confiança de que o resumo seja fiel ao teor da decisão – um ponto onde guardrails de verificação também poderiam ser aplicados para garantir que nenhuma nuance importante foi “perdida na tradução” automática.
* **Análise Estratégica e Suporte ao Contencioso:** Algumas startups oferecem IAs voltadas a insights estratégicos. A  *JUIT* , por exemplo, aplica IA para  **interpretar textos legais, sugerir estratégias processuais e até auxiliar na redação de petições** , analisando um banco extenso de precedentes para ajudar advogados na tomada de decisões[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). Esse tipo de ferramenta vai além do documento único – ela busca padrões em casos similares, possivelmente apontando qual linha de argumento teve sucesso em situações parecidas, ou quais julgados apoiarão determinada tese jurídica. É um uso promissor de IA para ampliar a visão do advogado sobre seu caso, mas que também traz o risco inerente de confiar cegamente em sugestões da máquina.
* **Assistentes Jurídicos Generalistas:** Grandes modelos internacionais e soluções amplas também estão sendo incorporados na área legal brasileira. Um exemplo notável é o  **Harvey** , um assistente jurídico baseado em IA avançada (inicieiamente construído sobre GPT) que foi adotado por escritórios globais e agora chega ao Brasil. Ele é capaz de **analisar documentos volumosos, redigir contratos e responder consultas** com base em modelos treinados em vasta jurisprudência mundial[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). Além dele, ferramentas não específicas do direito como **Copilot (da Microsoft)** e futuros modelos como **Gemini (do Google)** são mencionados como utilizáveis na advocacia, para geração de textos, síntese de documentos e respostas rápidas integradas a softwares jurídicos[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). A própria migração dessas tecnologias para o ecossistema jurídico indica que há demandas por produtividade e que as Big Tech estão adaptando seus produtos para usuários do Direito. Entretanto, um desafio aqui é que modelos generalistas nem sempre  **capturam as sutilezas do ordenamento jurídico local ou a língua portuguesa jurídica** . Muitos LLMs globais têm desempenho mais fraco em português jurídico, podendo cometer erros de tradução de termos técnicos ou deixar de reconhecer contextos legais brasileiros. Essa lacuna está sendo endereçada pelo surgimento de modelos nativos: recentemente, o **Jurema-7B** foi lançado como o primeiro LLM jurídico de código aberto treinado com dados nacionais (parceria entre NeuralMind e Escavador). Por ser um modelo ajustado a partir do Qwen 7B e focado no direito brasileiro, o Jurema obteve desempenho superior em benchmarks de português jurídico, incluindo um conjunto de questões da prova da OAB[neuralmind.ai](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=,quest%C3%B5es%20de%20n%C3%ADvel%20educacional%20amplo). Esse resultado demonstra a importância de  **modelos linguísticos calibrados ao contexto local** , tanto em compreensão de idioma quanto em *compliance* com leis (ex: respeito à LGPD embutido no treinamento)[neuralmind.ai](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=3.%20)[neuralmind.ai](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=2.%20).
* **Adoção Institucional de IA no Judiciário:** Não são apenas empresas e escritórios que têm investido em IA – os próprios órgãos de Justiça brasileiros iniciaram projetos. O Supremo Tribunal Federal (STF), por exemplo, implementou em 2023-2024 um sistema de **IA generativa para auxiliar na elaboração de minutas de decisões, resumos e relatórios**[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). A promessa é aumentar a eficiência, automatizando partes burocráticas da redação e deixando magistrados focarem mais na análise jurídica em si. Porém, esse movimento também gerou debates sobre limites éticos e necessidade de regulamentação do uso de IA em decisões judiciais[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=Tecnologia%20e%20Justi%C3%A7a%3A%20O%20papel,no%20Direito%20e%20seus%20limites). Casos polêmicos, como uma sentença supostamente gerada por IA no TJ/SP, reforçam a preocupação de que **alguma forma de controle humano e validação seja obrigatória** – afinal, a autoridade decisória não pode ser delegada integralmente a um algoritmo. Aqui novamente vemos a relevância de  *guardrails* : se IAs vão auxiliar juízes, precisam ter travas para não inserir dados incorretos nos relatórios ou enviesar conclusões de forma sutil. A confiança do público na Justiça poderia ser abalada caso uma “alucinação” de IA passasse despercebida em um acórdão, por exemplo.

Em síntese, o panorama atual mostra **ganhos significativos de produtividade e acesso à informação jurídica** trazidos pela IA. Ferramentas já conseguem rascunhar petições complexas em minutos, resumir milhares de páginas de processos ou encontrar aquela jurisprudência “agulha no palheiro” quase instantaneamente. No entanto,  **persistem desafios cruciais** : (a) garantir a **veracidade e precisão** do que é produzido (evitando gafes como a do advogado que citou cases inexistentes[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=)), (b) assegurar o **respeito à privacidade e à ética** profissional (por ex., filtrar dados confidenciais, cumprir LGPD[neuralmind.ai](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=3.%20)), (c) adaptar os modelos à **linguagem jurídica brasileira** e às constantes atualizações legislativas, e (d) tornar essas soluções acessíveis e confiáveis o bastante para uso amplo, sem que advogados temam serem “substituídos” ou prejudicados pela tecnologia. Esses pontos revelam oportunidades de inovação, como veremos a seguir.

## Lacunas e Oportunidades Identificadas

Com base na pesquisa acima, podemos destacar algumas **lacunas na aplicação de IA no direito brasileiro** que um projeto inovador poderia abordar:

* **Confiabilidade e Redução de Alucinações:** Há uma necessidade evidente de **garantir a veracidade das respostas** fornecidas por IAs jurídicas. Erros factuais ou citações fabricadas podem ter consequências graves em peças processuais. Embora algumas ferramentas aleguem ter “embasamento rastreável”, casos recentes mostram que essa questão não está totalmente resolvida[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). Portanto, uma oportunidade é desenvolver sistemas com **múltiplos mecanismos de verificação** – por exemplo, a IA só responde a perguntas jurídicas com trechos de leis/julgados extraídos de fontes oficiais ( *Retrieval Augmentation* ), exibindo as referências exatas. Camadas de guardrail (como citado em Fareed Khan) adicionam outra proteção: um módulo final pode cruzar cada citação na resposta com bancos de dados jurídicos reais, *validando que ela existe e está pertinente*[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,Integration%20and%20The%20Aegis%20Scorecard). Essa abordagem diferenciaria a solução pela  **confiabilidade** , algo essencial para adoção pelos profissionais.
* **Compliance com LGPD e Sigilo Profissional:** Muitos escritórios e órgãos públicos são reticentes em usar IA na nuvem (ex.: ChatGPT) por temores de violação da confidencialidade ou da Lei Geral de Proteção de Dados. De fato, estudo da FGV apontou que as principais plataformas generativas do mercado **ainda falham em aspectos de transparência e conformidade com a LGPD**[neuralmind.ai](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=3.%20). Há espaço para uma IA jurídica que seja **“privacy first”** – que opere localmente ou em ambiente controlado, ou que implemente técnicas de anonimização automática de informações sensíveis. Por exemplo, um projeto poderia incluir um *guardrail* na entrada (Layer 1) que detecta CPFs, nomes ou segredos de negócio em um prompt e os mascara antes de enviar ao LLM externo, prevenindo vazamento de dados pessoais. Alternativamente, usar um modelo open-source nacional (como Jurema-7B) dentro do próprio computador/servidor do advogado eliminaria a necessidade de enviar dados a terceiros. Soluções focadas em compliance teriam  **alto apelo em setores regulados** , permitindo adoção mais ampla de IA.
* **Transparência e Explicabilidade:** Outro gap é a falta de explicação das IAs para suas sugestões. Advogados e juízes tradicionalmente justificam cada passo do raciocínio; se um assistente de IA sugere uma estratégia ou uma cláusula contratual, seria valioso que ele também **explique o porquê** – citando jurisprudência de apoio, ou apontando riscos mitigados. Incorporar funções de **“chain-of-thought” explicável** (possivelmente apresentando ao usuário a linha de raciocínio interna validada pelo Layer 2 dos guardrails) pode aumentar a confiança e também servir de aprendizado para o profissional. Essa transparência alinha-se à ideia de  *AI auditável* , importante na seara jurídica.
* **Atualização Contínua frente à Legislação Mutável:** No Brasil, leis e súmulas mudam com frequência. Uma lacuna das ferramentas atuais pode ser a atualização. Modelos estáticos ficam obsoletos rapidamente quanto a novos entendimentos dos tribunais. Um projeto inovador poderia focar em um  **pipeline de atualização automática de conhecimento** , integrando fontes como o Diário Oficial, sites do Planalto (leis federais) e jurisprudências mais recentes em uma base de conhecimento para o agente. Isso combinado a RAG garantiria respostas sempre baseadas no estado atual do direito, algo que poucos produtos garantem hoje.
* **Acesso à Justiça e Cidadão Comum:** Embora muitas IAs estejam voltadas ao uso por advogados, existe também a oportunidade de criar ferramentas que ajudem diretamente os cidadãos a navegar em questões jurídicas básicas. Um *chatbot* orientativo, por exemplo, poderia explicar em linguagem simples direitos do consumidor ou passos para acessar a Justiça gratuita. Claro que aqui há limite ético para não configurar aconselhamento jurídico indevido; contudo, sob supervisão da OAB, uma solução open-source voltada à educação jurídica popular teria grande  **impacto social** . O hackathon explicitamente valoriza ampliar acesso à Justiça, então um projeto nesse viés – *por exemplo, um agente inteligente que triagem casos para defensoria pública ou oriente pessoas sobre documentos necessários para determinados pedidos legais* – pode se destacar, desde que bem documentado e com as devidas ressalvas (tal agente poderia, inclusive, ter *guardrails* para **recomendar procurar um advogado humano** em situações complexas, garantindo que sabe seus limites).
* **Integração com Fluxos de Trabalho Jurídicos:** Por fim, há espaço para inovação em como as IAs se encaixam no dia a dia do advogado. Uma ideia é  **agentes especializados cooperando** : imagine um agente que lê um contrato e destaca cláusulas problemáticas, passando para outro agente que sugere redações alternativas, e então a um terceiro que compara com a jurisprudência para ver se aquela cláusula já causou litígio antes. Esses agentes em série, cada um com *skill* diferente, poderiam ser orquestrados (usando frameworks tipo LangChain, etc.) para automatizar tarefas complexas ponta-a-ponta. Montar um *workflow* desse tipo com verificações em cada etapa exemplifica bem o tema “agentes inteligentes” do hackathon e resolveria problemas de produtividade em consultivo e contencioso.

## Proposta de Projeto Inovador: **Assistente Jurídico Guardrail-Br**

Com base nas análises e lacunas acima, delineamos uma proposta de solução para apresentar no hackathon da OAB-PR. O projeto, que podemos chamar provisoriamente de  **“Guardrail-Br: Agente Jurídico de IA Seguro”** , seria um  **assistente de IA para advogados focado no ordenamento brasileiro, construido com camadas robustas de segurança e verificações** . A seguir, resumimos os principais elementos e diferenciais dessa ideia:

* **Arquitetura de Agentes Multi-camada:** O Guardrail-Br adotaria a filosofia de pipeline em três camadas. Primeiramente, um **Agente Principal** (baseado em um LLM poderoso como GPT-4 ou um modelo aberto fine-tunado no direito brasileiro) responderia perguntas jurídicas, geraria minutas de documentos ou executaria tarefas (como preencher um modelo de contrato) conforme solicitado pelo usuário. Em paralelo, implementaríamos  **agentes supervisores em cada etapa** : um módulo de *Pre-check* (Layer 1) inspecionaria o prompt do usuário em busca de informações sensíveis ou pedidos potencialmente problemáticos. Por exemplo, se o usuário tentar consultar “dados de processo sigiloso X” ou inserir informações pessoais de um terceiro, o sistema pode alertar sobre sigilo/LGPD e exigir confirmação ou anonimizar dados[neuralmind.ai](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=3.%20). Também poderia rejeitar tarefas que claramente violem ética (p.ex.: “escreva uma petição caluniosa contra alguém”). Com o prompt saneado, o Agente Principal gera uma resposta, porém  **antes de retornar ao usuário entra o Layer 2** , onde um **Agente Validador de Plano** examina a cadeia de raciocínio. Aqui utilizaríamos a capacidade de obter a “razão” do LLM (via técnicas de *chain-of-thought* ou  *plan output* ) e aplicar regras: se o plano indica, por exemplo, consulta a uma base de dados, esse agente verifica se a fonte consultada é confiável e permitida; se o plano sugere uma estratégia jurídica, verifica se não contraria normas (ex.: citar jurisprudência já superada por súmula vinculante). Esse agente de Layer 2 poderia ser outro modelo de IA menor treinado para detectar riscos no plano (um uso de  *AI-on-AI* ), ou até envolver um humano no loop para revisar casos duvidosos[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=%2A%20AI,Integration%20and%20The%20Aegis%20Scorecard). Finalmente, no **Layer 3, o Agente Auditor de Saída** revisaria a resposta final do sistema. Este componente cruzaria todas as afirmações factuais com um **banco de dados jurídico** (legislação e jurisprudência atualizadas) para checar acurácia. Implementaríamos, por exemplo, uma  **verificação automática de citações** : se a resposta diz “conforme o art. 5º, inciso II da CF/88...”, o agente buscaria na Constituição o texto do inciso para ver se corresponde ao contexto citado; se a resposta menciona um caso “Recurso Especial 12345 do STJ”, ele consulta o repositório de jurisprudência para conferir se tal caso existe e se a ementa confere[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,Integration%20and%20The%20Aegis%20Scorecard). Qualquer inconsistência flagrada faz o Layer 3 segurar a resposta e marcar para revisão (solicitando ao Agente Principal refinar a saída com base correta, ou último caso avisando ao usuário que precisa de validação humana). Somente após passar por essas três instâncias é que a resposta confiável e sanitizada chega ao usuário final.
* **Base de Conhecimento Confiável (RAG):** Para garantir precisão, o Guardrail-Br integraria um módulo de  ***Retrieval-Augmented Generation*** . Ou seja, antes de gerar uma resposta narrativa, o agente faria consultas em fontes autorizadas: legislação (Constituição, códigos, leis federais do site Planalto, legislação estadual/municipal se relevante), súmulas e jurisprudência (por exemplo, usando APIs de tribunais ou repositórios públicos), doutrina básica e possivelmente um banco de dados de peças/modelos. Isso significa que a resposta da IA estaria **ancorada em trechos concretos** dessas fontes, citando-as explicitamente. Assim, o advogado usuário pode verificar facilmente os fundamentos. Essa técnica reduz bastante a chance de alucinação, pois transforma a tarefa em “resumir e combinar informações reais recuperadas” em vez de inventar do zero[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=)[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). Um diferencial é usar fontes em português e atualizadas: por exemplo, se em novembro/2025 uma nova lei for promulgada, o bot poderia indexá-la e considerar em respostas já no hackathon. Essa atualização contínua alinhada à legislação nacional seria um ponto forte (talvez até usando *web scraping* controlado do Diário Oficial ou integrações com bancos de dados jurídicos abertos). Em resumo, o Guardrail-Br funcionaria como um **“Copilot jurídico”** que *sempre mostra as referências* do que afirma – muito semelhante a ter um estagiário que ao responder algo já te entrega as cópias dos julgados e artigos de lei pertinentes.
* **Modelo Linguístico Local e Especializado:** Para o núcleo gerador, privilegiaríamos modelos alinhados ao português jurídico. Uma opção é aproveitar o  **Jurema-7B** , dado que é open-source e comprovou performance superior em questões da OAB e compreensão de termos legais brasileiros[neuralmind.ai](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=,quest%C3%B5es%20de%20n%C3%ADvel%20educacional%20amplo). Embora 7B parâmetros seja modesto comparado a um GPT-4, ele pode ser suficiente quando usado em conjunto com RAG (já que não precisa “saber tudo” de cabeça, apenas articular as informações recuperadas). Poderíamos fine-tunar o Jurema ligeiramente dentro do tempo disponível, adicionando instruções de formatação de petições ou pareceres. Alternativamente, poderíamos usar API de um modelo maior (GPT-4) para a geração principal e empregar o Jurema como verificador ou para etapas internas. Essa combinação de modelos  **aproveita o melhor de cada** : a criatividade e fluência de um LLM grande, com a precisão e conformidade de um modelo treinado localmente. Importante: se usar APIs externas (OpenAI, etc.), cuidaríamos da anonimização dos dados enviados, para atender a preocupação de privacidade (por exemplo, transformando nomes reais em códigos temporários antes de enviar ao modelo cloud, e revertendo depois localmente).
* **Camada de Segurança Inspirada no Aegis:** Embora implementar todo o protocolo Aegis seja complexo para um hackathon, adotaríamos princípios dele para fortalecer o sistema. Por exemplo, cada agente no pipeline poderia ter um **ID digital** e assinaria suas ações, permitindo auditoria posterior de quem (qual módulo) gerou qual parte da resposta – isso traz **responsabilização** dentro do sistema multiagente. Além disso, poderíamos usar criptografia de chaves públicas internamente: se o módulo de recuperação de jurisprudência acessa um banco sensível, os dados trafegariam cifrados, prevenindo espionagem. Finalmente, no que tange a compliance, poderíamos integrar uma **lista de políticas** (regras da OAB, LGPD, etc.) que seriam automaticamente checadas em cada resposta por meio de *prompts* de validação ou regex. Por exemplo, uma política “não revelar informações pessoais” seria implementada e o sistema só liberaria a saída se passasse nesse teste – isso é análogo à ideia de ZKP/Halo2 do Aegis, embora em forma simplificada. Em suma, essas adições mostrariam uma preocupação especial com segurança e ética, alinhando o Guardrail-Br com o estado da arte acadêmico em segurança de IA[arxiv.org](https://arxiv.org/abs/2508.19267#:~:text=failures%2C%20that%20traditional%20cybersecurity%20paradigms,Our%20quantitative%20evaluation)[arxiv.org](https://arxiv.org/abs/2508.19267#:~:text=validate%20the%20protocol%20against%20the,for%20safe%2C%20scalable%20autonomous%20AI).
* **Caso de Uso Demonstrativo:** Podemos ilustrar o funcionamento com um cenário: imagine um advogado perguntando ao assistente  *“Elabore uma petição inicial de ação indenizatória por dano moral contra uma operadora de telecomunicações, que cortou indevidamente o serviço do cliente. Baseie na jurisprudência atual do STJ”* . O Guardrail-Br rodaria assim: o Layer 1 detecta se há dados pessoais no prompt (digamos, nome do cliente); se houver, poderia já sugerir “[Nome do Cliente]” em vez do real. Em seguida, o módulo de *retrieval* busca jurisprudência do STJ sobre corte indevido de serviço/telefonia e acha, por exemplo, um REsp recente com indenização concedida. Passa isso ao modelo gerador, que produz um rascunho de petição estruturada (fatos, fundamentos, pedidos), citando aquele julgado do STJ e artigos do CDC. O Layer 2 analisa o plano: vê que o modelo pretende argumentar violação do art. 14 do CDC (serviço defeituoso) e usar dano moral presumido – são estratégias juridicamente válidas, então nada a bloquear; porém, nota que o plano do modelo ia mencionar um valor X de indenização sem justificar com base em precedentes. O Layer 2 pode então ajustar o plano para incluir uma breve pesquisa de valores em casos análogos ou pelo menos um alerta para o advogado personalizar o valor. O modelo gera a petição final com essas melhorias. Agora entra Layer 3: ele verifica que o REsp citado realmente existe e está corretamente descrito; confere que o art. 14 do CDC de fato trata de responsabilidade do fornecedor por defeitos (evitando erro de artigo); e passa um filtro de compliance (por exemplo, se a petição xingasse a operadora com adjetivos ofensivos – algo que o LLM *poderia* fazer se o advogado escrevesse de forma emocional – o Layer 3 limparia linguagem imprópria, mantendo tom profissional). Com tudo validado, o documento final é entregue ao usuário, completo em poucos minutos e pronto para revisão final humana. Esse fluxo demonstra  **eficiência com segurança** : mesmo acelerando o trabalho, o sistema mantém o advogado no controle e evita armadilhas comuns de IAs.
* **Alinhamento aos Critérios do Hackathon:** O projeto Guardrail-Br atinge diretamente os pontos que a banca deve avaliar. Em  **inovação** , combina de forma original conceitos de agentes em camadas (pouco explorado em soluções comerciais atuais) com foco específico nas dores do direito brasileiro – até incorporando pesquisa de ponta (Aegis, guardrails) num protótipo funcional. Em  **aplicabilidade** , a solução resolve problemas reais: advogados ganham um copiloto confiável que economiza tempo mas não compromete qualidade, e escritórios podem adotá-lo sem ferir sigilo. A **documentação aberta** permitiria que a comunidade jurídica e de TI aprimorasse a ferramenta com novos módulos (ex: adicionar verificações para outras áreas do direito, ou integrar a base de jurisprudência de um estado específico), exatamente o que a OAB-PR deseja com o repositório público[oabpr.org.br](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=Seguindo%20uma%20pol%C3%ADtica%20de%20acesso,profissionais%20de%20todo%20o%20pa%C3%ADs). Quanto ao  **impacto social** , um assistente assim poderia ser distribuído amplamente, inclusive para jovens advogados ou defensores com poucos recursos, nivelando o acesso à inteligência artificial jurídica de ponta. Com menos documentos com erros ou peças mal fundamentadas sendo protocoladas, o Judiciário também ganha em eficiência (evitando trabalho extra de analisar petições ineptas ou corrigir mal entendidos gerados por IA). Em suma, o Guardrail-Br tenderia a  **aumentar a confiança no uso da IA no meio jurídico** , desbloqueando seu potencial sem descuidar da responsabilidade.

## Ideias Complementares e Possíveis *Pivots*

Caso se avalie que a abordagem de *guardrails* multicamadas não seja a mais criativa para vencer o hackathon (por talvez focar muito em segurança e menos em novidade funcional), a pesquisa levanta também outras possíveis direções de projeto, que poderíamos incorporar ou pivotar:

* **Plataforma de Educação Jurídica com IA:** Aproveitando as capacidades de linguagem dos LLMs, poder-se-ia criar uma plataforma onde cidadãos ou estudantes interagem com um “professor jurídico virtual”. Diferente de chatbots genéricos, este estaria conectado a uma base de leis simplificadas e explicações em português claro. O diferencial seria um modo de  **explicação passo-a-passo** : por exemplo, alguém pergunta “Quais são meus direitos se meu voo atrasar?” e a IA, em vez de dar só um texto corrido, faz perguntas ao usuário (agente conversacional) para entender o caso concreto e então fornece um guia de ações (ex: “Você tem direito a assistência da companhia aérea após X horas de atraso, conforme Resolução 400 da ANAC[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). Quer que eu gere uma carta de reclamação baseada nisso?”). Esse tipo de agente orientador com interface amigável poderia ampliar o acesso à justiça informacional. Para não concorrer com a ideia principal, poderíamos até usar o Guardrail-Br como motor por trás e só mudar a *persona* de saída. Mas se fosse um pivot total, focaríamos em interfaces e gamificação do conhecimento jurídico, algo diferente do que empresas fazem hoje.
* **IA para Gestão Judiciária:** Outra ideia é desviar o foco para dentro do Judiciário: propor um agente que auxilie juízes e servidores. Por exemplo, um  **priorizador inteligente de casos** , que lê as iniciais de processos e sinaliza quais parecem mais urgentes ou quais têm conexões com repercussão geral, etc. Ou um **verificador de minutas** que o juiz possa rodar antes de assinar, que alertaria: “sua decisão cita um artigo de lei revogado” ou “use esta frase padrão para concessão de tutela, conforme recomendação do CNJ”. Esse tipo de ferramenta ainda não é comum e atenderia a um público diferente (juízes em vez de advogados), mas mostra impacto sistêmico. Para hackathon, talvez manter foco na advocacia (como pede o edital) seja melhor – contudo, poderíamos posicionar o Guardrail-Br como adaptável a esse uso (um modo “magistrado” que inverte a função: em vez de rascunhar petições, rascunha decisões, com guardrails para evitar contradições ou citação errada de jurisprudência).
* **Controle de Bias e Diversidade nas Decisões de IA:** Um insight da literatura e eventos (como apontado por especialistas no Migalhas) é que os dados e algoritmos carregam vieses[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). Um projeto inovador poderia focar nisso, criando, por exemplo, um **“validador de viés”** para produtos de IA jurídica. Seria uma ferramenta que analisa as saídas de um modelo e verifica se há linguagem tendenciosa, discriminação implícita ou favorecimento sistemático contra um grupo (por ex., sempre negando benefícios para um certo perfil de parte). Isso seria particularmente inovador e com impacto social, pois ajudaria a **manter a imparcialidade e isonomia** no uso de IA. No contexto do Guardrail-Br, poderíamos incorporar um módulo assim no Layer 3, que revisaria a decisão sugerida pela IA para possíveis preconceitos (ex: gênero das partes influenciando tom da redação). Ressaltar essa funcionalidade poderia agradar jurados preocupados com ética e igualdade, tornando o projeto ainda mais completo.

Em conclusão, a confluência de **tecnologias de IA de ponta** com as **demandas específicas do direito brasileiro** abre um leque de possibilidades de projetos inovadores. A proposta central aqui – um assistente jurídico com guardrails multicamadas – aproveita ideias dos links pesquisados (pipeline agentivo seguro[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,it%E2%80%99s%20sent%20to%20the%20user), framework formal de segurança[arxiv.org](https://arxiv.org/abs/2508.19267#:~:text=failures%2C%20that%20traditional%20cybersecurity%20paradigms,Our%20quantitative%20evaluation)) e responde a falhas reais observadas no uso de IA na advocacia (alucinações de jurisprudência, problemas de compliance). Ao mesmo tempo, permanecemos atentos a outros caminhos criativos revelados pela pesquisa (educação legal automatizada, viés em IA, etc.), podendo ajustá-la conforme o feedback ou a composição da equipe. Com essa base de pesquisa profunda, estamos preparados para desenvolver um **projeto consistente, original e de alto impacto** no Hackathon de IA da OAB-PR 2025 – unindo **inovação tecnológica e responsabilidade jurídica** para transformar a forma como advogados e cidadãos interagem com o sistema de justiça.

 **Fontes Utilizadas:**

* Fareed Khan. *“Building a Multi-Layered Agentic Guardrail Pipeline to Reduce Hallucinations and Mitigate Risk.”* Level Up Coding, Oct. 2025[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,it%E2%80%99s%20sent%20to%20the%20user)[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,Integration%20and%20The%20Aegis%20Scorecard).
* Sai T. R. Adapala & Yashwanth R. Alugubelly. *“The Aegis Protocol: A Foundational Security Framework for Autonomous AI Agents.”* arXiv preprint 2508.19267 (Aug. 2025)[arxiv.org](https://arxiv.org/abs/2508.19267#:~:text=failures%2C%20that%20traditional%20cybersecurity%20paradigms,Our%20quantitative%20evaluation)[arxiv.org](https://arxiv.org/abs/2508.19267#:~:text=validate%20the%20protocol%20against%20the,for%20safe%2C%20scalable%20autonomous%20AI).
* OAB/PR – Comissão de Inovação. *“Hackathon de Inteligência Artificial da OAB-PR promete maratona de inovação voltada à criação de soluções jurídicas.”* Notícias OABPR, 15 out. 2025[oabpr.org.br](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=O%20desafio%20proposto%20pelo%20Hackathon,aplica%C3%A7%C3%A3o%20pr%C3%A1tica%20e%20documenta%C3%A7%C3%A3o%20aberta)[oabpr.org.br](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=As%20tr%C3%AAs%20equipes%20com%20os,e%20impacto%20social%20da%20proposta).
* **Migalhas** – Da Redação. *“Confira 8 ferramentas de IA que facilitam a rotina dos advogados.”* Migalhas Quentes, 7 fev. 2025[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=)[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=).
* Jurídico AI – *Apresentação da Plataforma.* (Site oficial, acessado em out. 2025)[juridico.ai](https://juridico.ai/#:~:text=Pe%C3%A7as%20geradas%20por%20uma%20IA,treinada%20em%20direito%20brasileiro)[juridico.ai](https://juridico.ai/#:~:text=Suas%20pe%C3%A7as%20criadas%20por%20uma,legisla%C3%A7%C3%A3o%2C%20jurisprud%C3%AAncia%20e%20doutrina%20brasileiras).
* Cria.AI – *Apresentação da Plataforma.* (Site oficial, acessado em out. 2025)[criaai.app.br](https://criaai.app.br/#:~:text=A%C2%A0Cria,performance%20para%20profissionais%20do%20direito).
* Fernanda Brandão (NeuralMind). *“A importância de desenvolver LLMs para o contexto brasileiro.”* Blog NeuralMind, 15 out. 2025[neuralmind.ai](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=3.%20)[neuralmind.ai](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=,quest%C3%B5es%20de%20n%C3%ADvel%20educacional%20amplo).
* Migalhas – Renata Nilsson. *“Tecnologia e Justiça: O papel da IA no Direito e seus limites.”* Migalhas de Peso, 13 jun. 2023[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=Tecnologia%20e%20Justi%C3%A7a%3A%20O%20papel,no%20Direito%20e%20seus%20limites).

<iframe height="1" width="1" aria-hidden="true"></iframe>

# IA no Direito Brasileiro: Soluções Inovadoras e Uso de *Guardrails*

## Pipeline Multi-Camadas de *Guardrails* (Redução de Alucinações)

![https://github.com/FareedKhan-dev/agentic-guardrails](blob:https://chatgpt.com/82bf20b0-228e-4c07-b822-bf5d5777e696)

*Figura: Exemplo de pipeline avançado com múltiplas camadas de **guardrails** para agentes de IA. O Layer 1 filtra entradas maliciosas, o Layer 2 valida o plano de ação interno do agente, e o Layer 3 sanitiza a resposta final antes de enviá-la ao usuário.*

 Uma recente abordagem para aumentar a confiabilidade de sistemas de IA é a implantação de *guardrails* (trilhos de segurança) em múltiplas camadas. Em essência, a ideia é criar um **pipeline de defesa em profundidade** para agentes de IA ou soluções de *Retrieval-Augmented Generation* (RAG). Cada camada atua como uma barreira independente para mitigar riscos como alucinações (invenção de fatos), violações de compliance, prompts maliciosos ou saídas inadequadas[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=Guardrails,includes%20components%20such%20as%20%E2%80%A6)[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,it%E2%80%99s%20sent%20to%20the%20user). Por exemplo, no **Layer 1 (Entrada)** o sistema realiza verificações rápidas na consulta do usuário, bloqueando imediatamente entradas maliciosas, irrelevantes ou que violem políticas antes que cheguem ao agente principal[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,it%E2%80%99s%20sent%20to%20the%20user). Em seguida, o **Layer 2 (Plano de Ação)** inspeciona o raciocínio interno ou *chain-of-thought* do agente, validando o plano de ação gerado. Se o agente planeja uma ação arriscada ou contrária às regras, essa camada pode barrar ou ajustar o curso antes da execução[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=agent.%20,compliant%20intentions%20before%20execution). Por fim, o **Layer 3 (Saída)** atua como um filtro final sobre a resposta produzida: verifica se há informações imprecisas ou potencialmente inseguras, assegura conformidade jurídica e sanitiza a linguagem antes de apresentar o resultado ao usuário[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=before%20execution.%20,it%E2%80%99s%20sent%20to%20the%20user). Esse modelo em três camadas — entrada segura, plano monitorado e saída verificada — garante que mesmo que alguma falha passe por uma camada, outra mais adiante possa detectá-la e corrigi-la[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=Guardrails,includes%20components%20such%20as%20%E2%80%A6)[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,it%E2%80%99s%20sent%20to%20the%20user). Em implementações recentes, essa abordagem incluiu até uma etapa de **verificação de citações e fatos** no Layer 3, visando reduzir drasticamente as alucinações factuais em domínios críticos[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,Integration%20and%20The%20Aegis%20Scorecard).

 No contexto jurídico, um pipeline multi-camadas de guardrails é especialmente valioso. Considere que advogados dependem da exatidão de citações de leis e jurisprudências nos documentos: uma IA generativa sem controles pode inventar precedentes ou artigos de lei inexistentes, o que é inaceitável. Houve caso no Brasil em que um advogado apresentou um Habeas Corpus redigido por IA contendo  **jurisprudência falsa** , tentando induzir erro no tribunal – o que levou a advertência formal pelo TJ/SC[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). *Guardrails* bem projetados podem prevenir esse tipo de situação, pois obrigariam o sistema a **fundamentar cada afirmação em fontes confiáveis** ou alertariam o usuário sobre conteúdo não verificado. Além disso, camadas de segurança podem impor limites éticos e de conformidade: por exemplo, bloqueando respostas que violem o Código de Ética da OAB ou que exponham dados sigilosos de clientes. Assim, inspirando-se nesse artigo de Fareed Khan (2025) sobre  *“Agentic Guardrail Pipeline”* , pode-se integrar um **assistente jurídico de IA** com múltiplos filtros de segurança, ganhando a confiança dos profissionais do Direito ao minimizar alucinações e riscos legais[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,it%E2%80%99s%20sent%20to%20the%20user).

## O Protocolo  *Aegis* : Segurança Formal para Agentes Autônomos de IA

Enquanto os *guardrails* acima tratam de filtragens e validações mais voltadas ao conteúdo gerado, o **Protocolo Aegis** (proposto por Adapala & Alugubelly, 2025) traz uma perspectiva complementar de **segurança de infraestrutura** para ecossistemas de agentes de IA. Trata-se de um **framework de segurança fundamentado** em três pilares tecnológicos[arxiv.org](https://arxiv.org/abs/2508.19267#:~:text=failures%2C%20that%20traditional%20cybersecurity%20paradigms,Our%20quantitative%20evaluation): *(1)* **Identidade não-falsificável** dos agentes via identificadores descentralizados (DIDs), garantindo que cada agente possua credenciais únicas e verificáveis; *(2)* **Integridade na comunicação** entre agentes, utilizando criptografia pós-quântica padronizada pelo NIST, para evitar interceptações ou alterações maliciosas nas mensagens trocadas; e *(3)*  **Compliance verificável por provas de conhecimento zero (ZKP)** , através do sistema Halo2, assegurando que agentes ajam conforme políticas pré-definidas **sem expor dados sensíveis**[arxiv.org](https://arxiv.org/abs/2508.19267#:~:text=failures%2C%20that%20traditional%20cybersecurity%20paradigms,Our%20quantitative%20evaluation). Em outras palavras, um agente poderia provar criptograficamente que seguiu certas regras (por exemplo, “não acessar dados sigilosos além do escopo permitido”) sem revelar qual dado específico foi acessado, graças às ZKPs.

 Os autores do Aegis validaram o protocolo contra um modelo de adversário avançado e o avaliaram via simulação com 1.000 agentes, observando **taxa de sucesso zero** para 20 mil tentativas de ataque quando as camadas Aegis estavam ativadas[arxiv.org](https://arxiv.org/abs/2508.19267#:~:text=preserving%20policy%20compliance%20using%20the,a%20reproducible%20baseline%20for%20future). Isso sugere que a combinação de identidade forte, comunicações seguras e cumprimento verificável de regras pode praticamente blindar um sistema multiagente contra diversos vetores de ataque. Embora esse nível de segurança seja avançado e voltado a agentes autônomos complexos, **os conceitos podem inspirar soluções jurídicas** inovadoras. Por exemplo, em um projeto de IA jurídica, poderíamos implementar **identificação segura de agentes** para assegurar que apenas usuários/autores autorizados gerem certos tipos de documentos, e usar criptografia robusta para proteger comunicações envolvendo dados de clientes (conforme exige a confidencialidade profissional). Além disso, o uso de **políticas verificáveis** via algoritmos de compliance poderia garantir aderência à LGPD e outras normas: cada resposta do agente viria acompanhada de uma “prova” de que nenhum dado pessoal foi indevidamente exposto durante o processamento, por exemplo. Em suma, o protocolo Aegis mostra que é possível elevar a confiança em agentes de IA a um patamar quase  *à prova de falhas* , algo desejável em aplicações críticas como no Direito[arxiv.org](https://arxiv.org/abs/2508.19267#:~:text=failures%2C%20that%20traditional%20cybersecurity%20paradigms,Our%20quantitative%20evaluation)[arxiv.org](https://arxiv.org/abs/2508.19267#:~:text=validate%20the%20protocol%20against%20the,for%20safe%2C%20scalable%20autonomous%20AI).

## Hackathon de IA da OAB-PR: Objetivos e Contexto

O terceiro link fornecido é a notícia oficial do  **Hackathon de Inteligência Artificial da OAB Paraná 2025** , que estabelece o cenário onde essa pesquisa será aplicada. Trata-se de uma maratona de inovação nos dias 6 e 7 de dezembro de 2025 (inscrições de 21/10 a 24/11) voltada à **criação de soluções jurídicas abertas usando IA**[oabpr.org.br](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=A%20OAB%20Paran%C3%A1%20abre%20na,sede%20da%20seccional%2C%20em%20Curitiba)[oabpr.org.br](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=O%20desafio%20proposto%20pelo%20Hackathon,aplica%C3%A7%C3%A3o%20pr%C3%A1tica%20e%20documenta%C3%A7%C3%A3o%20aberta). Diferentemente de hackathons tradicionais de programação pura, este evento foca em  **engenharia de *prompts* e agentes inteligentes** , incentivando participantes a utilizarem modelos já disponíveis (GPT-4, Microsoft Copilot, Claude, Gemini, etc.) para resolver problemas reais da advocacia e ampliar o acesso à Justiça[oabpr.org.br](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=O%20desafio%20proposto%20pelo%20Hackathon,aplica%C3%A7%C3%A3o%20pr%C3%A1tica%20e%20documenta%C3%A7%C3%A3o%20aberta). Ou seja, não é obrigatório saber codar; o diferencial estará na criatividade da ideia, na aplicação prática e na documentação. A OAB-PR enfatiza que **todos os projetos deverão ter formato aberto e código/documentação disponibilizados em repositório público** sob licença permissiva[oabpr.org.br](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=documenta%C3%A7%C3%A3o%20aberta). Essa política de *open source* visa possibilitar que as soluções criadas sejam adotadas e aprimoradas posteriormente por escritórios, departamentos jurídicos e profissionais de todo o país, maximizando o impacto.

 Os critérios de avaliação incluem  **inovação** ,  **aplicabilidade prática** , **clareza da documentação** e **impacto social**[oabpr.org.br](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=As%20tr%C3%AAs%20equipes%20com%20os,e%20impacto%20social%20da%20proposta). As equipes vencedoras (compostas por 3 a 6 integrantes, incluindo ao menos dois advogados ou estudantes de Direito) receberão prêmios em dinheiro e serão julgadas por uma banca mista de especialistas do meio jurídico e tecnológico[oabpr.org.br](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=As%20tr%C3%AAs%20equipes%20com%20os,e%20impacto%20social%20da%20proposta). Esse contexto deixa claro que, para se destacar, um projeto deve apresentar  **originalidade na ideia** , ao mesmo tempo em que resolve um problema concreto dos profissionais do Direito ou da sociedade (acesso à informação e Justiça), e que tenha potencial de ser usado na prática real. Além disso, a menção específica a “prompts e agentes” indica que soluções envolvendo **Agentes de IA encadeados, fluxos automáticos de trabalho com LLMs, ou integrações criativas entre ferramentas** estão alinhadas ao que os organizadores esperam. Em suma, o hackathon da OAB-PR é uma oportunidade de propor um  **protótipo inovador de IA jurídica** , aproveitando tecnologias de ponta já existentes, mas customizando-as ao contexto brasileiro e aos valores da advocacia (ética, privacidade, acesso equânime).

## Soluções de IA já Aplicadas no Direito Brasileiro

Antes de delinear novas ideias, vale mapear brevemente o estado atual das  **ferramentas de IA jurídica no Brasil** , até para identificar lacunas a serem preenchidas. Nos últimos anos, surgiram diversas soluções comerciais e experimentais integrando IA ao cotidiano dos advogados brasileiros:

* **Automação de Documentos e Peças Processuais:** Ferramentas como  *Jurídico AI* ,  *Lawx.ai* , *ChatADV* e *Cria.AI* permitem gerar petições, contratos e pareceres automaticamente a partir de poucos dados de entrada. Essas IAs são  **treinadas especificamente em legislação, jurisprudência e doutrina brasileiras** , garantindo que a linguagem jurídica e os fundamentos legais estejam alinhados ao ordenamento nacional[juridico.ai](https://juridico.ai/#:~:text=Pe%C3%A7as%20geradas%20por%20uma%20IA,treinada%20em%20direito%20brasileiro)[juridico.ai](https://juridico.ai/#:~:text=Suas%20pe%C3%A7as%20criadas%20por%20uma,legisla%C3%A7%C3%A3o%2C%20jurisprud%C3%AAncia%20e%20doutrina%20brasileiras). Por exemplo, a plataforma Jurídico AI afirma ter uma IA atualizada diariamente com leis e jurisprudência do país, capaz de produzir peças personalizadas de alta qualidade em minutos[juridico.ai](https://juridico.ai/#:~:text=Gere%20pe%C3%A7as%20espec%C3%ADficas%20para%20os,seus%20casos%20jur%C3%ADdicos)[juridico.ai](https://juridico.ai/#:~:text=Tenha%20pe%C3%A7as%20completas%20e%20ricas,com%20informa%C3%A7%C3%A3o%20jur%C3%ADdica%20consistente). Já a Cria.AI destaca que seus documentos vêm com  **“embasamento rastreável e jurisprudências reais e precisas”** , contabilizando milhares de horas de trabalho poupadas aos advogados[criaai.app.br](https://criaai.app.br/#:~:text=A%C2%A0Cria,performance%20para%20profissionais%20do%20direito). Ou seja, há um esforço claro de diferenciar essas ferramentas de um ChatGPT genérico, oferecendo conteúdo já fundamentado nas fontes corretas (o que sugere uso de técnicas de *retrieval* ou bases de dados internas). Ainda assim, a cautela é necessária: mesmo soluções boas podem eventualmente referenciar casos equivocados, cabendo ao advogado revisar o material.
* **Pesquisa Jurídica e Jurisprudência:** A busca por precedentes e entendimentos jurisprudenciais ganhou agilidade com IAs como *Turivius* e  *Inspira* . Essas plataformas utilizam NLP para  **organizar e resumir decisões judiciais** , permitindo encontrar precedentes relevantes de forma mais eficiente do que pesquisas manuais em diários oficiais[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). O Inspira, por exemplo, fornece *resumos automáticos de decisões* e até colaboração em tempo real na análise de documentos legais[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). Isso facilita o trabalho, mas novamente depende-se da confiança de que o resumo seja fiel ao teor da decisão – um ponto onde guardrails de verificação também poderiam ser aplicados para garantir que nenhuma nuance importante foi “perdida na tradução” automática.
* **Análise Estratégica e Suporte ao Contencioso:** Algumas startups oferecem IAs voltadas a insights estratégicos. A  *JUIT* , por exemplo, aplica IA para  **interpretar textos legais, sugerir estratégias processuais e até auxiliar na redação de petições** , analisando um banco extenso de precedentes para ajudar advogados na tomada de decisões[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). Esse tipo de ferramenta vai além do documento único – ela busca padrões em casos similares, possivelmente apontando qual linha de argumento teve sucesso em situações parecidas, ou quais julgados apoiarão determinada tese jurídica. É um uso promissor de IA para ampliar a visão do advogado sobre seu caso, mas que também traz o risco inerente de confiar cegamente em sugestões da máquina.
* **Assistentes Jurídicos Generalistas:** Grandes modelos internacionais e soluções amplas também estão sendo incorporados na área legal brasileira. Um exemplo notável é o  **Harvey** , um assistente jurídico baseado em IA avançada (inicieiamente construído sobre GPT) que foi adotado por escritórios globais e agora chega ao Brasil. Ele é capaz de **analisar documentos volumosos, redigir contratos e responder consultas** com base em modelos treinados em vasta jurisprudência mundial[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). Além dele, ferramentas não específicas do direito como **Copilot (da Microsoft)** e futuros modelos como **Gemini (do Google)** são mencionados como utilizáveis na advocacia, para geração de textos, síntese de documentos e respostas rápidas integradas a softwares jurídicos[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). A própria migração dessas tecnologias para o ecossistema jurídico indica que há demandas por produtividade e que as Big Tech estão adaptando seus produtos para usuários do Direito. Entretanto, um desafio aqui é que modelos generalistas nem sempre  **capturam as sutilezas do ordenamento jurídico local ou a língua portuguesa jurídica** . Muitos LLMs globais têm desempenho mais fraco em português jurídico, podendo cometer erros de tradução de termos técnicos ou deixar de reconhecer contextos legais brasileiros. Essa lacuna está sendo endereçada pelo surgimento de modelos nativos: recentemente, o **Jurema-7B** foi lançado como o primeiro LLM jurídico de código aberto treinado com dados nacionais (parceria entre NeuralMind e Escavador). Por ser um modelo ajustado a partir do Qwen 7B e focado no direito brasileiro, o Jurema obteve desempenho superior em benchmarks de português jurídico, incluindo um conjunto de questões da prova da OAB[neuralmind.ai](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=,quest%C3%B5es%20de%20n%C3%ADvel%20educacional%20amplo). Esse resultado demonstra a importância de  **modelos linguísticos calibrados ao contexto local** , tanto em compreensão de idioma quanto em *compliance* com leis (ex: respeito à LGPD embutido no treinamento)[neuralmind.ai](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=3.%20)[neuralmind.ai](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=2.%20).
* **Adoção Institucional de IA no Judiciário:** Não são apenas empresas e escritórios que têm investido em IA – os próprios órgãos de Justiça brasileiros iniciaram projetos. O Supremo Tribunal Federal (STF), por exemplo, implementou em 2023-2024 um sistema de **IA generativa para auxiliar na elaboração de minutas de decisões, resumos e relatórios**[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). A promessa é aumentar a eficiência, automatizando partes burocráticas da redação e deixando magistrados focarem mais na análise jurídica em si. Porém, esse movimento também gerou debates sobre limites éticos e necessidade de regulamentação do uso de IA em decisões judiciais[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=Tecnologia%20e%20Justi%C3%A7a%3A%20O%20papel,no%20Direito%20e%20seus%20limites). Casos polêmicos, como uma sentença supostamente gerada por IA no TJ/SP, reforçam a preocupação de que **alguma forma de controle humano e validação seja obrigatória** – afinal, a autoridade decisória não pode ser delegada integralmente a um algoritmo. Aqui novamente vemos a relevância de  *guardrails* : se IAs vão auxiliar juízes, precisam ter travas para não inserir dados incorretos nos relatórios ou enviesar conclusões de forma sutil. A confiança do público na Justiça poderia ser abalada caso uma “alucinação” de IA passasse despercebida em um acórdão, por exemplo.

Em síntese, o panorama atual mostra **ganhos significativos de produtividade e acesso à informação jurídica** trazidos pela IA. Ferramentas já conseguem rascunhar petições complexas em minutos, resumir milhares de páginas de processos ou encontrar aquela jurisprudência “agulha no palheiro” quase instantaneamente. No entanto,  **persistem desafios cruciais** : (a) garantir a **veracidade e precisão** do que é produzido (evitando gafes como a do advogado que citou cases inexistentes[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=)), (b) assegurar o **respeito à privacidade e à ética** profissional (por ex., filtrar dados confidenciais, cumprir LGPD[neuralmind.ai](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=3.%20)), (c) adaptar os modelos à **linguagem jurídica brasileira** e às constantes atualizações legislativas, e (d) tornar essas soluções acessíveis e confiáveis o bastante para uso amplo, sem que advogados temam serem “substituídos” ou prejudicados pela tecnologia. Esses pontos revelam oportunidades de inovação, como veremos a seguir.

## Lacunas e Oportunidades Identificadas

Com base na pesquisa acima, podemos destacar algumas **lacunas na aplicação de IA no direito brasileiro** que um projeto inovador poderia abordar:

* **Confiabilidade e Redução de Alucinações:** Há uma necessidade evidente de **garantir a veracidade das respostas** fornecidas por IAs jurídicas. Erros factuais ou citações fabricadas podem ter consequências graves em peças processuais. Embora algumas ferramentas aleguem ter “embasamento rastreável”, casos recentes mostram que essa questão não está totalmente resolvida[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). Portanto, uma oportunidade é desenvolver sistemas com **múltiplos mecanismos de verificação** – por exemplo, a IA só responde a perguntas jurídicas com trechos de leis/julgados extraídos de fontes oficiais ( *Retrieval Augmentation* ), exibindo as referências exatas. Camadas de guardrail (como citado em Fareed Khan) adicionam outra proteção: um módulo final pode cruzar cada citação na resposta com bancos de dados jurídicos reais, *validando que ela existe e está pertinente*[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,Integration%20and%20The%20Aegis%20Scorecard). Essa abordagem diferenciaria a solução pela  **confiabilidade** , algo essencial para adoção pelos profissionais.
* **Compliance com LGPD e Sigilo Profissional:** Muitos escritórios e órgãos públicos são reticentes em usar IA na nuvem (ex.: ChatGPT) por temores de violação da confidencialidade ou da Lei Geral de Proteção de Dados. De fato, estudo da FGV apontou que as principais plataformas generativas do mercado **ainda falham em aspectos de transparência e conformidade com a LGPD**[neuralmind.ai](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=3.%20). Há espaço para uma IA jurídica que seja **“privacy first”** – que opere localmente ou em ambiente controlado, ou que implemente técnicas de anonimização automática de informações sensíveis. Por exemplo, um projeto poderia incluir um *guardrail* na entrada (Layer 1) que detecta CPFs, nomes ou segredos de negócio em um prompt e os mascara antes de enviar ao LLM externo, prevenindo vazamento de dados pessoais. Alternativamente, usar um modelo open-source nacional (como Jurema-7B) dentro do próprio computador/servidor do advogado eliminaria a necessidade de enviar dados a terceiros. Soluções focadas em compliance teriam  **alto apelo em setores regulados** , permitindo adoção mais ampla de IA.
* **Transparência e Explicabilidade:** Outro gap é a falta de explicação das IAs para suas sugestões. Advogados e juízes tradicionalmente justificam cada passo do raciocínio; se um assistente de IA sugere uma estratégia ou uma cláusula contratual, seria valioso que ele também **explique o porquê** – citando jurisprudência de apoio, ou apontando riscos mitigados. Incorporar funções de **“chain-of-thought” explicável** (possivelmente apresentando ao usuário a linha de raciocínio interna validada pelo Layer 2 dos guardrails) pode aumentar a confiança e também servir de aprendizado para o profissional. Essa transparência alinha-se à ideia de  *AI auditável* , importante na seara jurídica.
* **Atualização Contínua frente à Legislação Mutável:** No Brasil, leis e súmulas mudam com frequência. Uma lacuna das ferramentas atuais pode ser a atualização. Modelos estáticos ficam obsoletos rapidamente quanto a novos entendimentos dos tribunais. Um projeto inovador poderia focar em um  **pipeline de atualização automática de conhecimento** , integrando fontes como o Diário Oficial, sites do Planalto (leis federais) e jurisprudências mais recentes em uma base de conhecimento para o agente. Isso combinado a RAG garantiria respostas sempre baseadas no estado atual do direito, algo que poucos produtos garantem hoje.
* **Acesso à Justiça e Cidadão Comum:** Embora muitas IAs estejam voltadas ao uso por advogados, existe também a oportunidade de criar ferramentas que ajudem diretamente os cidadãos a navegar em questões jurídicas básicas. Um *chatbot* orientativo, por exemplo, poderia explicar em linguagem simples direitos do consumidor ou passos para acessar a Justiça gratuita. Claro que aqui há limite ético para não configurar aconselhamento jurídico indevido; contudo, sob supervisão da OAB, uma solução open-source voltada à educação jurídica popular teria grande  **impacto social** . O hackathon explicitamente valoriza ampliar acesso à Justiça, então um projeto nesse viés – *por exemplo, um agente inteligente que triagem casos para defensoria pública ou oriente pessoas sobre documentos necessários para determinados pedidos legais* – pode se destacar, desde que bem documentado e com as devidas ressalvas (tal agente poderia, inclusive, ter *guardrails* para **recomendar procurar um advogado humano** em situações complexas, garantindo que sabe seus limites).
* **Integração com Fluxos de Trabalho Jurídicos:** Por fim, há espaço para inovação em como as IAs se encaixam no dia a dia do advogado. Uma ideia é  **agentes especializados cooperando** : imagine um agente que lê um contrato e destaca cláusulas problemáticas, passando para outro agente que sugere redações alternativas, e então a um terceiro que compara com a jurisprudência para ver se aquela cláusula já causou litígio antes. Esses agentes em série, cada um com *skill* diferente, poderiam ser orquestrados (usando frameworks tipo LangChain, etc.) para automatizar tarefas complexas ponta-a-ponta. Montar um *workflow* desse tipo com verificações em cada etapa exemplifica bem o tema “agentes inteligentes” do hackathon e resolveria problemas de produtividade em consultivo e contencioso.

## Proposta de Projeto Inovador: **Assistente Jurídico Guardrail-Br**

Com base nas análises e lacunas acima, delineamos uma proposta de solução para apresentar no hackathon da OAB-PR. O projeto, que podemos chamar provisoriamente de  **“Guardrail-Br: Agente Jurídico de IA Seguro”** , seria um  **assistente de IA para advogados focado no ordenamento brasileiro, construido com camadas robustas de segurança e verificações** . A seguir, resumimos os principais elementos e diferenciais dessa ideia:

* **Arquitetura de Agentes Multi-camada:** O Guardrail-Br adotaria a filosofia de pipeline em três camadas. Primeiramente, um **Agente Principal** (baseado em um LLM poderoso como GPT-4 ou um modelo aberto fine-tunado no direito brasileiro) responderia perguntas jurídicas, geraria minutas de documentos ou executaria tarefas (como preencher um modelo de contrato) conforme solicitado pelo usuário. Em paralelo, implementaríamos  **agentes supervisores em cada etapa** : um módulo de *Pre-check* (Layer 1) inspecionaria o prompt do usuário em busca de informações sensíveis ou pedidos potencialmente problemáticos. Por exemplo, se o usuário tentar consultar “dados de processo sigiloso X” ou inserir informações pessoais de um terceiro, o sistema pode alertar sobre sigilo/LGPD e exigir confirmação ou anonimizar dados[neuralmind.ai](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=3.%20). Também poderia rejeitar tarefas que claramente violem ética (p.ex.: “escreva uma petição caluniosa contra alguém”). Com o prompt saneado, o Agente Principal gera uma resposta, porém  **antes de retornar ao usuário entra o Layer 2** , onde um **Agente Validador de Plano** examina a cadeia de raciocínio. Aqui utilizaríamos a capacidade de obter a “razão” do LLM (via técnicas de *chain-of-thought* ou  *plan output* ) e aplicar regras: se o plano indica, por exemplo, consulta a uma base de dados, esse agente verifica se a fonte consultada é confiável e permitida; se o plano sugere uma estratégia jurídica, verifica se não contraria normas (ex.: citar jurisprudência já superada por súmula vinculante). Esse agente de Layer 2 poderia ser outro modelo de IA menor treinado para detectar riscos no plano (um uso de  *AI-on-AI* ), ou até envolver um humano no loop para revisar casos duvidosos[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=%2A%20AI,Integration%20and%20The%20Aegis%20Scorecard). Finalmente, no **Layer 3, o Agente Auditor de Saída** revisaria a resposta final do sistema. Este componente cruzaria todas as afirmações factuais com um **banco de dados jurídico** (legislação e jurisprudência atualizadas) para checar acurácia. Implementaríamos, por exemplo, uma  **verificação automática de citações** : se a resposta diz “conforme o art. 5º, inciso II da CF/88...”, o agente buscaria na Constituição o texto do inciso para ver se corresponde ao contexto citado; se a resposta menciona um caso “Recurso Especial 12345 do STJ”, ele consulta o repositório de jurisprudência para conferir se tal caso existe e se a ementa confere[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,Integration%20and%20The%20Aegis%20Scorecard). Qualquer inconsistência flagrada faz o Layer 3 segurar a resposta e marcar para revisão (solicitando ao Agente Principal refinar a saída com base correta, ou último caso avisando ao usuário que precisa de validação humana). Somente após passar por essas três instâncias é que a resposta confiável e sanitizada chega ao usuário final.
* **Base de Conhecimento Confiável (RAG):** Para garantir precisão, o Guardrail-Br integraria um módulo de  ***Retrieval-Augmented Generation*** . Ou seja, antes de gerar uma resposta narrativa, o agente faria consultas em fontes autorizadas: legislação (Constituição, códigos, leis federais do site Planalto, legislação estadual/municipal se relevante), súmulas e jurisprudência (por exemplo, usando APIs de tribunais ou repositórios públicos), doutrina básica e possivelmente um banco de dados de peças/modelos. Isso significa que a resposta da IA estaria **ancorada em trechos concretos** dessas fontes, citando-as explicitamente. Assim, o advogado usuário pode verificar facilmente os fundamentos. Essa técnica reduz bastante a chance de alucinação, pois transforma a tarefa em “resumir e combinar informações reais recuperadas” em vez de inventar do zero[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=)[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). Um diferencial é usar fontes em português e atualizadas: por exemplo, se em novembro/2025 uma nova lei for promulgada, o bot poderia indexá-la e considerar em respostas já no hackathon. Essa atualização contínua alinhada à legislação nacional seria um ponto forte (talvez até usando *web scraping* controlado do Diário Oficial ou integrações com bancos de dados jurídicos abertos). Em resumo, o Guardrail-Br funcionaria como um **“Copilot jurídico”** que *sempre mostra as referências* do que afirma – muito semelhante a ter um estagiário que ao responder algo já te entrega as cópias dos julgados e artigos de lei pertinentes.
* **Modelo Linguístico Local e Especializado:** Para o núcleo gerador, privilegiaríamos modelos alinhados ao português jurídico. Uma opção é aproveitar o  **Jurema-7B** , dado que é open-source e comprovou performance superior em questões da OAB e compreensão de termos legais brasileiros[neuralmind.ai](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=,quest%C3%B5es%20de%20n%C3%ADvel%20educacional%20amplo). Embora 7B parâmetros seja modesto comparado a um GPT-4, ele pode ser suficiente quando usado em conjunto com RAG (já que não precisa “saber tudo” de cabeça, apenas articular as informações recuperadas). Poderíamos fine-tunar o Jurema ligeiramente dentro do tempo disponível, adicionando instruções de formatação de petições ou pareceres. Alternativamente, poderíamos usar API de um modelo maior (GPT-4) para a geração principal e empregar o Jurema como verificador ou para etapas internas. Essa combinação de modelos  **aproveita o melhor de cada** : a criatividade e fluência de um LLM grande, com a precisão e conformidade de um modelo treinado localmente. Importante: se usar APIs externas (OpenAI, etc.), cuidaríamos da anonimização dos dados enviados, para atender a preocupação de privacidade (por exemplo, transformando nomes reais em códigos temporários antes de enviar ao modelo cloud, e revertendo depois localmente).
* **Camada de Segurança Inspirada no Aegis:** Embora implementar todo o protocolo Aegis seja complexo para um hackathon, adotaríamos princípios dele para fortalecer o sistema. Por exemplo, cada agente no pipeline poderia ter um **ID digital** e assinaria suas ações, permitindo auditoria posterior de quem (qual módulo) gerou qual parte da resposta – isso traz **responsabilização** dentro do sistema multiagente. Além disso, poderíamos usar criptografia de chaves públicas internamente: se o módulo de recuperação de jurisprudência acessa um banco sensível, os dados trafegariam cifrados, prevenindo espionagem. Finalmente, no que tange a compliance, poderíamos integrar uma **lista de políticas** (regras da OAB, LGPD, etc.) que seriam automaticamente checadas em cada resposta por meio de *prompts* de validação ou regex. Por exemplo, uma política “não revelar informações pessoais” seria implementada e o sistema só liberaria a saída se passasse nesse teste – isso é análogo à ideia de ZKP/Halo2 do Aegis, embora em forma simplificada. Em suma, essas adições mostrariam uma preocupação especial com segurança e ética, alinhando o Guardrail-Br com o estado da arte acadêmico em segurança de IA[arxiv.org](https://arxiv.org/abs/2508.19267#:~:text=failures%2C%20that%20traditional%20cybersecurity%20paradigms,Our%20quantitative%20evaluation)[arxiv.org](https://arxiv.org/abs/2508.19267#:~:text=validate%20the%20protocol%20against%20the,for%20safe%2C%20scalable%20autonomous%20AI).
* **Caso de Uso Demonstrativo:** Podemos ilustrar o funcionamento com um cenário: imagine um advogado perguntando ao assistente  *“Elabore uma petição inicial de ação indenizatória por dano moral contra uma operadora de telecomunicações, que cortou indevidamente o serviço do cliente. Baseie na jurisprudência atual do STJ”* . O Guardrail-Br rodaria assim: o Layer 1 detecta se há dados pessoais no prompt (digamos, nome do cliente); se houver, poderia já sugerir “[Nome do Cliente]” em vez do real. Em seguida, o módulo de *retrieval* busca jurisprudência do STJ sobre corte indevido de serviço/telefonia e acha, por exemplo, um REsp recente com indenização concedida. Passa isso ao modelo gerador, que produz um rascunho de petição estruturada (fatos, fundamentos, pedidos), citando aquele julgado do STJ e artigos do CDC. O Layer 2 analisa o plano: vê que o modelo pretende argumentar violação do art. 14 do CDC (serviço defeituoso) e usar dano moral presumido – são estratégias juridicamente válidas, então nada a bloquear; porém, nota que o plano do modelo ia mencionar um valor X de indenização sem justificar com base em precedentes. O Layer 2 pode então ajustar o plano para incluir uma breve pesquisa de valores em casos análogos ou pelo menos um alerta para o advogado personalizar o valor. O modelo gera a petição final com essas melhorias. Agora entra Layer 3: ele verifica que o REsp citado realmente existe e está corretamente descrito; confere que o art. 14 do CDC de fato trata de responsabilidade do fornecedor por defeitos (evitando erro de artigo); e passa um filtro de compliance (por exemplo, se a petição xingasse a operadora com adjetivos ofensivos – algo que o LLM *poderia* fazer se o advogado escrevesse de forma emocional – o Layer 3 limparia linguagem imprópria, mantendo tom profissional). Com tudo validado, o documento final é entregue ao usuário, completo em poucos minutos e pronto para revisão final humana. Esse fluxo demonstra  **eficiência com segurança** : mesmo acelerando o trabalho, o sistema mantém o advogado no controle e evita armadilhas comuns de IAs.
* **Alinhamento aos Critérios do Hackathon:** O projeto Guardrail-Br atinge diretamente os pontos que a banca deve avaliar. Em  **inovação** , combina de forma original conceitos de agentes em camadas (pouco explorado em soluções comerciais atuais) com foco específico nas dores do direito brasileiro – até incorporando pesquisa de ponta (Aegis, guardrails) num protótipo funcional. Em  **aplicabilidade** , a solução resolve problemas reais: advogados ganham um copiloto confiável que economiza tempo mas não compromete qualidade, e escritórios podem adotá-lo sem ferir sigilo. A **documentação aberta** permitiria que a comunidade jurídica e de TI aprimorasse a ferramenta com novos módulos (ex: adicionar verificações para outras áreas do direito, ou integrar a base de jurisprudência de um estado específico), exatamente o que a OAB-PR deseja com o repositório público[oabpr.org.br](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=Seguindo%20uma%20pol%C3%ADtica%20de%20acesso,profissionais%20de%20todo%20o%20pa%C3%ADs). Quanto ao  **impacto social** , um assistente assim poderia ser distribuído amplamente, inclusive para jovens advogados ou defensores com poucos recursos, nivelando o acesso à inteligência artificial jurídica de ponta. Com menos documentos com erros ou peças mal fundamentadas sendo protocoladas, o Judiciário também ganha em eficiência (evitando trabalho extra de analisar petições ineptas ou corrigir mal entendidos gerados por IA). Em suma, o Guardrail-Br tenderia a  **aumentar a confiança no uso da IA no meio jurídico** , desbloqueando seu potencial sem descuidar da responsabilidade.

## Ideias Complementares e Possíveis *Pivots*

Caso se avalie que a abordagem de *guardrails* multicamadas não seja a mais criativa para vencer o hackathon (por talvez focar muito em segurança e menos em novidade funcional), a pesquisa levanta também outras possíveis direções de projeto, que poderíamos incorporar ou pivotar:

* **Plataforma de Educação Jurídica com IA:** Aproveitando as capacidades de linguagem dos LLMs, poder-se-ia criar uma plataforma onde cidadãos ou estudantes interagem com um “professor jurídico virtual”. Diferente de chatbots genéricos, este estaria conectado a uma base de leis simplificadas e explicações em português claro. O diferencial seria um modo de  **explicação passo-a-passo** : por exemplo, alguém pergunta “Quais são meus direitos se meu voo atrasar?” e a IA, em vez de dar só um texto corrido, faz perguntas ao usuário (agente conversacional) para entender o caso concreto e então fornece um guia de ações (ex: “Você tem direito a assistência da companhia aérea após X horas de atraso, conforme Resolução 400 da ANAC[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). Quer que eu gere uma carta de reclamação baseada nisso?”). Esse tipo de agente orientador com interface amigável poderia ampliar o acesso à justiça informacional. Para não concorrer com a ideia principal, poderíamos até usar o Guardrail-Br como motor por trás e só mudar a *persona* de saída. Mas se fosse um pivot total, focaríamos em interfaces e gamificação do conhecimento jurídico, algo diferente do que empresas fazem hoje.
* **IA para Gestão Judiciária:** Outra ideia é desviar o foco para dentro do Judiciário: propor um agente que auxilie juízes e servidores. Por exemplo, um  **priorizador inteligente de casos** , que lê as iniciais de processos e sinaliza quais parecem mais urgentes ou quais têm conexões com repercussão geral, etc. Ou um **verificador de minutas** que o juiz possa rodar antes de assinar, que alertaria: “sua decisão cita um artigo de lei revogado” ou “use esta frase padrão para concessão de tutela, conforme recomendação do CNJ”. Esse tipo de ferramenta ainda não é comum e atenderia a um público diferente (juízes em vez de advogados), mas mostra impacto sistêmico. Para hackathon, talvez manter foco na advocacia (como pede o edital) seja melhor – contudo, poderíamos posicionar o Guardrail-Br como adaptável a esse uso (um modo “magistrado” que inverte a função: em vez de rascunhar petições, rascunha decisões, com guardrails para evitar contradições ou citação errada de jurisprudência).
* **Controle de Bias e Diversidade nas Decisões de IA:** Um insight da literatura e eventos (como apontado por especialistas no Migalhas) é que os dados e algoritmos carregam vieses[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=). Um projeto inovador poderia focar nisso, criando, por exemplo, um **“validador de viés”** para produtos de IA jurídica. Seria uma ferramenta que analisa as saídas de um modelo e verifica se há linguagem tendenciosa, discriminação implícita ou favorecimento sistemático contra um grupo (por ex., sempre negando benefícios para um certo perfil de parte). Isso seria particularmente inovador e com impacto social, pois ajudaria a **manter a imparcialidade e isonomia** no uso de IA. No contexto do Guardrail-Br, poderíamos incorporar um módulo assim no Layer 3, que revisaria a decisão sugerida pela IA para possíveis preconceitos (ex: gênero das partes influenciando tom da redação). Ressaltar essa funcionalidade poderia agradar jurados preocupados com ética e igualdade, tornando o projeto ainda mais completo.

Em conclusão, a confluência de **tecnologias de IA de ponta** com as **demandas específicas do direito brasileiro** abre um leque de possibilidades de projetos inovadores. A proposta central aqui – um assistente jurídico com guardrails multicamadas – aproveita ideias dos links pesquisados (pipeline agentivo seguro[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,it%E2%80%99s%20sent%20to%20the%20user), framework formal de segurança[arxiv.org](https://arxiv.org/abs/2508.19267#:~:text=failures%2C%20that%20traditional%20cybersecurity%20paradigms,Our%20quantitative%20evaluation)) e responde a falhas reais observadas no uso de IA na advocacia (alucinações de jurisprudência, problemas de compliance). Ao mesmo tempo, permanecemos atentos a outros caminhos criativos revelados pela pesquisa (educação legal automatizada, viés em IA, etc.), podendo ajustá-la conforme o feedback ou a composição da equipe. Com essa base de pesquisa profunda, estamos preparados para desenvolver um **projeto consistente, original e de alto impacto** no Hackathon de IA da OAB-PR 2025 – unindo **inovação tecnológica e responsabilidade jurídica** para transformar a forma como advogados e cidadãos interagem com o sistema de justiça.

 **Fontes Utilizadas:**

* Fareed Khan. *“Building a Multi-Layered Agentic Guardrail Pipeline to Reduce Hallucinations and Mitigate Risk.”* Level Up Coding, Oct. 2025[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,it%E2%80%99s%20sent%20to%20the%20user)[github.com](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,Integration%20and%20The%20Aegis%20Scorecard).
* Sai T. R. Adapala & Yashwanth R. Alugubelly. *“The Aegis Protocol: A Foundational Security Framework for Autonomous AI Agents.”* arXiv preprint 2508.19267 (Aug. 2025)[arxiv.org](https://arxiv.org/abs/2508.19267#:~:text=failures%2C%20that%20traditional%20cybersecurity%20paradigms,Our%20quantitative%20evaluation)[arxiv.org](https://arxiv.org/abs/2508.19267#:~:text=validate%20the%20protocol%20against%20the,for%20safe%2C%20scalable%20autonomous%20AI).
* OAB/PR – Comissão de Inovação. *“Hackathon de Inteligência Artificial da OAB-PR promete maratona de inovação voltada à criação de soluções jurídicas.”* Notícias OABPR, 15 out. 2025[oabpr.org.br](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=O%20desafio%20proposto%20pelo%20Hackathon,aplica%C3%A7%C3%A3o%20pr%C3%A1tica%20e%20documenta%C3%A7%C3%A3o%20aberta)[oabpr.org.br](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=As%20tr%C3%AAs%20equipes%20com%20os,e%20impacto%20social%20da%20proposta).
* **Migalhas** – Da Redação. *“Confira 8 ferramentas de IA que facilitam a rotina dos advogados.”* Migalhas Quentes, 7 fev. 2025[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=)[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=).
* Jurídico AI – *Apresentação da Plataforma.* (Site oficial, acessado em out. 2025)[juridico.ai](https://juridico.ai/#:~:text=Pe%C3%A7as%20geradas%20por%20uma%20IA,treinada%20em%20direito%20brasileiro)[juridico.ai](https://juridico.ai/#:~:text=Suas%20pe%C3%A7as%20criadas%20por%20uma,legisla%C3%A7%C3%A3o%2C%20jurisprud%C3%AAncia%20e%20doutrina%20brasileiras).
* Cria.AI – *Apresentação da Plataforma.* (Site oficial, acessado em out. 2025)[criaai.app.br](https://criaai.app.br/#:~:text=A%C2%A0Cria,performance%20para%20profissionais%20do%20direito).
* Fernanda Brandão (NeuralMind). *“A importância de desenvolver LLMs para o contexto brasileiro.”* Blog NeuralMind, 15 out. 2025[neuralmind.ai](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=3.%20)[neuralmind.ai](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=,quest%C3%B5es%20de%20n%C3%ADvel%20educacional%20amplo).
* Migalhas – Renata Nilsson. *“Tecnologia e Justiça: O papel da IA no Direito e seus limites.”* Migalhas de Peso, 13 jun. 2023[migalhas.com.br](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=Tecnologia%20e%20Justi%C3%A7a%3A%20O%20papel,no%20Direito%20e%20seus%20limites).

Citations

[![](https://www.google.com/s2/favicons?domain=https://github.com&sz=32)GitHub - FareedKhan-dev/agentic-guardrails: Layered guardrails to make agentic AI safer and more reliable.https://github.com/FareedKhan-dev/agentic-guardrails](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=Guardrails,includes%20components%20such%20as%20%E2%80%A6)[![](https://www.google.com/s2/favicons?domain=https://github.com&sz=32)GitHub - FareedKhan-dev/agentic-guardrails: Layered guardrails to make agentic AI safer and more reliable.https://github.com/FareedKhan-dev/agentic-guardrails](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,it%E2%80%99s%20sent%20to%20the%20user)[![](https://www.google.com/s2/favicons?domain=https://github.com&sz=32)GitHub - FareedKhan-dev/agentic-guardrails: Layered guardrails to make agentic AI safer and more reliable.https://github.com/FareedKhan-dev/agentic-guardrails](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=agent.%20,compliant%20intentions%20before%20execution)[![](https://www.google.com/s2/favicons?domain=https://github.com&sz=32)GitHub - FareedKhan-dev/agentic-guardrails: Layered guardrails to make agentic AI safer and more reliable.https://github.com/FareedKhan-dev/agentic-guardrails](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=before%20execution.%20,it%E2%80%99s%20sent%20to%20the%20user)[![](https://www.google.com/s2/favicons?domain=https://github.com&sz=32)GitHub - FareedKhan-dev/agentic-guardrails: Layered guardrails to make agentic AI safer and more reliable.https://github.com/FareedKhan-dev/agentic-guardrails](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=,Integration%20and%20The%20Aegis%20Scorecard)[![](https://www.google.com/s2/favicons?domain=https://www.migalhas.com.br&sz=32)Confira 8 ferramentas de IA que facilitam a rotina dos advogados - Migalhashttps://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=)[![](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)[2508.19267] The Aegis Protocol: A Foundational Security Framework for Autonomous AI Agentshttps://arxiv.org/abs/2508.19267](https://arxiv.org/abs/2508.19267#:~:text=failures%2C%20that%20traditional%20cybersecurity%20paradigms,Our%20quantitative%20evaluation)[![](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)[2508.19267] The Aegis Protocol: A Foundational Security Framework for Autonomous AI Agentshttps://arxiv.org/abs/2508.19267](https://arxiv.org/abs/2508.19267#:~:text=preserving%20policy%20compliance%20using%20the,a%20reproducible%20baseline%20for%20future)[![](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)[2508.19267] The Aegis Protocol: A Foundational Security Framework for Autonomous AI Agentshttps://arxiv.org/abs/2508.19267](https://arxiv.org/abs/2508.19267#:~:text=validate%20the%20protocol%20against%20the,for%20safe%2C%20scalable%20autonomous%20AI)[Hackathon de Inteligência Artificial da OAB-PR promete maratona de inovação voltada à criação de soluções jurídicas - OABPRhttps://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=A%20OAB%20Paran%C3%A1%20abre%20na,sede%20da%20seccional%2C%20em%20Curitiba)[Hackathon de Inteligência Artificial da OAB-PR promete maratona de inovação voltada à criação de soluções jurídicas - OABPRhttps://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=O%20desafio%20proposto%20pelo%20Hackathon,aplica%C3%A7%C3%A3o%20pr%C3%A1tica%20e%20documenta%C3%A7%C3%A3o%20aberta)[Hackathon de Inteligência Artificial da OAB-PR promete maratona de inovação voltada à criação de soluções jurídicas - OABPRhttps://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=documenta%C3%A7%C3%A3o%20aberta)[Hackathon de Inteligência Artificial da OAB-PR promete maratona de inovação voltada à criação de soluções jurídicas - OABPRhttps://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=As%20tr%C3%AAs%20equipes%20com%20os,e%20impacto%20social%20da%20proposta)[Hackathon de Inteligência Artificial da OAB-PR promete maratona de inovação voltada à criação de soluções jurídicas - OABPRhttps://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=As%20tr%C3%AAs%20equipes%20com%20os,e%20impacto%20social%20da%20proposta)[![](https://www.google.com/s2/favicons?domain=https://juridico.ai&sz=32)Inteligência Artificial para Advogados - Jurídico AIhttps://juridico.ai/](https://juridico.ai/#:~:text=Pe%C3%A7as%20geradas%20por%20uma%20IA,treinada%20em%20direito%20brasileiro)[![](https://www.google.com/s2/favicons?domain=https://juridico.ai&sz=32)Inteligência Artificial para Advogados - Jurídico AIhttps://juridico.ai/](https://juridico.ai/#:~:text=Suas%20pe%C3%A7as%20criadas%20por%20uma,legisla%C3%A7%C3%A3o%2C%20jurisprud%C3%AAncia%20e%20doutrina%20brasileiras)[![](https://www.google.com/s2/favicons?domain=https://juridico.ai&sz=32)Inteligência Artificial para Advogados - Jurídico AIhttps://juridico.ai/](https://juridico.ai/#:~:text=Gere%20pe%C3%A7as%20espec%C3%ADficas%20para%20os,seus%20casos%20jur%C3%ADdicos)[![](https://www.google.com/s2/favicons?domain=https://juridico.ai&sz=32)Inteligência Artificial para Advogados - Jurídico AIhttps://juridico.ai/](https://juridico.ai/#:~:text=Tenha%20pe%C3%A7as%20completas%20e%20ricas,com%20informa%C3%A7%C3%A3o%20jur%C3%ADdica%20consistente)[![](https://www.google.com/s2/favicons?domain=https://criaai.app.br&sz=32)Cria.AI – Documentos Jurídicos com Inteligência Artificialhttps://criaai.app.br/](https://criaai.app.br/#:~:text=A%C2%A0Cria,performance%20para%20profissionais%20do%20direito)[![](https://www.google.com/s2/favicons?domain=https://www.migalhas.com.br&sz=32)Confira 8 ferramentas de IA que facilitam a rotina dos advogados - Migalhashttps://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=)[![](https://www.google.com/s2/favicons?domain=https://www.migalhas.com.br&sz=32)Confira 8 ferramentas de IA que facilitam a rotina dos advogados - Migalhashttps://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=)[![](https://www.google.com/s2/favicons?domain=https://www.migalhas.com.br&sz=32)Confira 8 ferramentas de IA que facilitam a rotina dos advogados - Migalhashttps://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=)[![](https://www.google.com/s2/favicons?domain=https://www.migalhas.com.br&sz=32)Confira 8 ferramentas de IA que facilitam a rotina dos advogados - Migalhashttps://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=)[![](https://www.google.com/s2/favicons?domain=https://www.migalhas.com.br&sz=32)Confira 8 ferramentas de IA que facilitam a rotina dos advogados - Migalhashttps://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=)[![](https://www.google.com/s2/favicons?domain=https://neuralmind.ai&sz=32)A importância de desenvolver LLMs para o contexto brasileirohttps://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=,quest%C3%B5es%20de%20n%C3%ADvel%20educacional%20amplo)[![](https://www.google.com/s2/favicons?domain=https://neuralmind.ai&sz=32)A importância de desenvolver LLMs para o contexto brasileirohttps://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=3.%20)[![](https://www.google.com/s2/favicons?domain=https://neuralmind.ai&sz=32)A importância de desenvolver LLMs para o contexto brasileirohttps://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=2.%20)[![](https://www.google.com/s2/favicons?domain=https://www.migalhas.com.br&sz=32)Confira 8 ferramentas de IA que facilitam a rotina dos advogados - Migalhashttps://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=)[![](https://www.google.com/s2/favicons?domain=https://www.migalhas.com.br&sz=32)Confira 8 ferramentas de IA que facilitam a rotina dos advogados - Migalhashttps://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=Tecnologia%20e%20Justi%C3%A7a%3A%20O%20papel,no%20Direito%20e%20seus%20limites)[![](https://www.google.com/s2/favicons?domain=https://github.com&sz=32)GitHub - FareedKhan-dev/agentic-guardrails: Layered guardrails to make agentic AI safer and more reliable.https://github.com/FareedKhan-dev/agentic-guardrails](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=%2A%20AI,Integration%20and%20The%20Aegis%20Scorecard)[Hackathon de Inteligência Artificial da OAB-PR promete maratona de inovação voltada à criação de soluções jurídicas - OABPRhttps://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=Seguindo%20uma%20pol%C3%ADtica%20de%20acesso,profissionais%20de%20todo%20o%20pa%C3%ADs)[![](https://www.google.com/s2/favicons?domain=https://www.migalhas.com.br&sz=32)Confira 8 ferramentas de IA que facilitam a rotina dos advogados - Migalhashttps://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=)[![](https://www.google.com/s2/favicons?domain=https://www.migalhas.com.br&sz=32)Confira 8 ferramentas de IA que facilitam a rotina dos advogados - Migalhashttps://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=)

All Sources

[![](https://www.google.com/s2/favicons?domain=https://github.com&sz=32)github](https://github.com/FareedKhan-dev/agentic-guardrails#:~:text=Guardrails,includes%20components%20such%20as%20%E2%80%A6)[![](https://www.google.com/s2/favicons?domain=https://www.migalhas.com.br&sz=32)migalhas.com](https://www.migalhas.com.br/quentes/424264/confira-8-ferramentas-de-ia-que-facilitam-a-rotina-dos-advogados#:~:text=)[![](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv](https://arxiv.org/abs/2508.19267#:~:text=failures%2C%20that%20traditional%20cybersecurity%20paradigms,Our%20quantitative%20evaluation)[oabpr.org](https://www.oabpr.org.br/hackathon-de-inteligencia-artificial-da-oab-pr-promete-maratona-de-inovacao-voltada-a-criacao-de-solucoes-juridicas/#:~:text=A%20OAB%20Paran%C3%A1%20abre%20na,sede%20da%20seccional%2C%20em%20Curitiba)[![](https://www.google.com/s2/favicons?domain=https://juridico.ai&sz=32)juridico](https://juridico.ai/#:~:text=Pe%C3%A7as%20geradas%20por%20uma%20IA,treinada%20em%20direito%20brasileiro)[![](https://www.google.com/s2/favicons?domain=https://criaai.app.br&sz=32)criaai.app](https://criaai.app.br/#:~:text=A%C2%A0Cria,performance%20para%20profissionais%20do%20direito)[![](https://www.google.com/s2/favicons?domain=https://neuralmind.ai&sz=32)neuralmind](https://neuralmind.ai/blog/a-import%C3%A2ncia-de-desenvolver-llms-para-o-contexto-brasileiro#:~:text=,quest%C3%B5es%20de%20n%C3%ADvel%20educacional%20amplo)
